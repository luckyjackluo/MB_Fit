{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MB-Fit Documentation (v1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the last decades, the branch of computational chemistry has played an important role in the study of energetic, dynamical and structural properties of chemical and physical processes such as vibrational spectra, phase diagrams, isomerization processes, chemical reactions... Computational chemistry provides a powerful tool to gain insights on the driving forces of these processes under the assumption that the energies, or more accurately, the energy differences, are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When exploring the potential energy surface (PES), there are several computational methods available. *Ab initio* methods provide an accurate solution, depending on the method itself and the basis set used, but the treatable system size is usually small, from a few atoms when using coupled-cluster theory, to a few hundreds of atoms when using density functional theory (DFT). These methods solve the Schrodinger Equation\n",
    "\n",
    "$$\\hat{H}\\Psi = E\\Psi$$\n",
    "\n",
    "for wavefunction methods such as Hartree-Fock, perturbation theory, or coupled-cluster, or the Kohn-Sham equations\n",
    "\n",
    "$$\\left( -\\frac{\\hbar ^2}{2m} \\nabla ^2 + v_{eff}(\\vec{r})\\right) = \\varepsilon _i \\varphi _i (\\vec{r})$$\n",
    "\n",
    "$$\\rho(\\vec{r}) = \\sum _i ^N \\left\\lvert\\varphi _i (\\vec{r}) \\right\\rvert ^2 \\label{eq:dens}$$\n",
    "\n",
    "in the case of DFT. Commonly, systems of interest can have thousands of atoms, and exploring the PES with *ab initio* methods is virtually impossible nowadays. However, one can go to the force field (FF) realm to find very simplified potential energy functions (PEFs) typically based on harmonic potentials for bonded interactions, Lennard-Jones potentials for non-bonded interactions, and point-charge electrostatic interactions. \n",
    "\n",
    "$$ $$\n",
    "\n",
    "These PEFs enable the treatment of tens of thousands of atoms, and can be further simplified by coarse-graining them to reach hundreds of thousands of atoms. However, the accuracy of FFs is not great. We can plot these different methods in a plot of size vs. accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/plot_methods.png\" alt=\"plotmethods\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, we would like to be in the predictive representation area: have a great accuracy and be able to treat large system sizes. Several approaches can be taken, and one of them is based on the many-body expansion (MBE) of the energy of a system, which can be decomposed as the sum of the one-body energy, plut the two body energy, plus the three-body energy, and so on, until the n-th body:\n",
    "\n",
    "$$ E_{\\text{N}}(1,\\dots,N) = \\sum_{i=1}^N V^{\\text{1B}}(i) + \\sum_{i<j}^NV^{\\text{2B}}(i,j) \n",
    "\t+ \\sum_{i<j<k}^N V^{\\text{3B}}(i,j,k) + \\dots + V^{\\text{NB}}(1,\\dots,N) $$\n",
    "\n",
    "where $V^{\\text{1B}}(i) = 0$ and $V^{\\text{1B}}(i) = E(i) - E_{\\text{eq}}(i)$ for atomic and molecular monomers, respectively. \n",
    "In the latter case, $V^{\\text{1B}}(i)$ corresponds to the one-body (1B) energy required to deform an individual monomer from its equilibrium geometry, and $V^{\\text{nB}}$ are the $n$-body (nB) energies defined recursively as\n",
    "\n",
    "$$ V^{\\text{nB}}(1,\\dots,n) = E_n(1,\\dots,n) - \\sum_iV^{\\text{1B}}(i) - \\sum_{i<j}V^{\\text{2B}}(i,j) - \\sum_{i<j<\\dots<n-1}V^{\\text{(n-1)B}}(i,j,\\dots,(n-1)) $$\n",
    "\n",
    "Since the MBE converges quickly for non-metallic systems such as CH$_4$ and H$_2$O, it provides a rigorous and efficient framework for the development of full-dimensional PEFs in which each individual term of the MBE can be separately determined from high-level electronic structure calculations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides with the infrastructure to generate one- and two-body PEFs for small molecules, i.e. molecules that have a maximum bond distance between atoms of 4, such as ethane, carbon dioxide, or the case we will present in this document, ammonia. The different PEFs, functional form and terms will be presented as they appear. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the requirements here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will serve as a template that one can use for other small molecules. The first step to ensure that the library can be imported is to add the path to the MB-Fit library to the Python path. To do so, first define the `MBFIT_HOME` environment variable to point to the folder where `MB-fit` is located, and source the file `mbfit.sh` located inside `MBFIT_HOME`. If this step has not been done before opening the notebook, please copy these lines in a bash terminal and reopen the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "export MBFIT_HOME=\"PATH/TO/MBFIT\"\n",
    "source ${MBFIT_HOME}/mbfit.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two lines of code will enable access to the `mbfit` module from any Python script. Now the library should be imported without any error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mbfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-body PEF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Between 2013 and 2014, the Paesani lab published a full dimentional many-body PEF for water. MB-pol is based on the many-body expansion of the total energy of a system, and  it uses different expressions for the different many-body terms. The one-body term was borrowed from the PEF developed by Partridge and . This surface is fitted to reproduce energies from ab initio data, experimental rotational constants, vibrational spectra, and other properties. I was shown to be an excellent model to describe the behavior of an isolated water molecule. From now on, when we talk about MB-pol, $V^{\\text{1B}} = V^{\\text{1B}}_{\\text{PS}}$\n",
    "\n",
    "The one-body energy is also known as the distorion energy, and is typically described by force fields using harmonic fucntions for bonds and angles, and other simple functional forms for dihedrals and inversion angles. Within the MB-nrg framework, the distortion energy will be described with PIPs. The goal of this section is to obtain $V^{\\text{1B}}(\\vec{r})$ Contrariely as for MB-pol, we will develop a PEF for any other molecule, since there are not too many surfaces in the literature with similar accuracy as the one for water.\n",
    "\n",
    "The functional form that MB-nrg uses is a set of permutationally invariant polynomials that are a function of the internal distances of the atoms in the monomer.\n",
    "\n",
    "$$ V^{\\text{1B}} = \\sum _i A_i P[\\xi _a  \\xi _b \\dots \\xi _n] $$\n",
    "\n",
    "$A_i$ is a linear constant, and P is a set of permutations that make the system permutationally invariant with respect to the variables $\\xi _j$ that are present in the element $i$ of the sum. The polynomial variables $\\xi$ are a function of a distance between two atoms $r$, and can have different functional forms with the condition that they must decay to 0 when $r \\rightarrow \\infty$. Examples of possible acceptable variable functional forms are Morse type variables ($\\xi(r) = e^{-kr}$) or Coulomb type variables ($\\xi(r) = e^{-kr}/r$)\n",
    "\n",
    "This next part of this text will show how to generate the necessary data to obtain these linear ($A_i$) and non-linear ($k_j$) parameters that allow the best description of the reference PES."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Electronic structure calculation details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MB-Fit supports two different software packages to perform calculations: `QChem` and `Psi4`. There is no difference in using one or the other in terms of obtaining the PEF. For this example we will use `Psi4`, along with the DFT functional $\\omega$B97M-V and the aug-cc-pvtz basis set. All this information will be stored in variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Electronic structure software"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The options for the package are `\"qchem\"` to use QChem, and `\"psi4\"` to use Psi4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"qchem\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Electronic structure method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The options here are any method that the ES software can handle. The most common methods to use are any supported DFT functional and coupled-cluster theory (CCSD(T)):\n",
    "```\n",
    "method = \"HF\"     # will use Hartree-Fock\n",
    "method = \"MP2\"    # will use the Moller-Plesset perturbation theory of order 2\n",
    "method = \"PBE0\"   # will use the DFT functional PBE0\n",
    "```\n",
    "In this example we will use $\\omega$B97M-V. This hybrid functional has been shown to have coupled-cluster accuracy for one- and two-body interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = \"wb97m-v\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basis set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of the basis set will determine how reliable are the calculated energies. A larger basis set will be closer to the limit of the level of theory used, but it will be also more computationally expensive. For DFT, aug-cc-pvtz is close to the complete basis set limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis = \"aug-cc-pvtz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computation details and extra options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, an electronic structure package needs to have the memory and the number of threads that will be used. This can be specified with the variables `num_threads` and `memory`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of threads to use\n",
    "num_threads = 2\n",
    "\n",
    "# Amount of memory to use\n",
    "memory = \"4GB\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A part from the basic optiones defined above, sometimes it is needed to define extra variables or parameters in the electronic structure calculation, such as number of SCF iterations, number of geometry optimization steps, energy thresholds... These options can be passed as a dictionary to the corresponding calculations. Each option has a keyword in the corresponding electronic structure software. For example, in QCHEM, to increase the number of SCF iterations, we need to define the keyword `MAX_SCF_CYCLES`, and to increase the maximum number of optimization steps, the keyword `GEOM_OPT_MAX_CYCLES`. We can add these options into a dictionarythat we will then pass to the calculation routines:\n",
    "```\n",
    "qm_options = {\"MAX_SCF_CYCLES\" : 100, \"GEOM_OPT_MAX_CYCLES\" : 80}\n",
    "```\n",
    "which would be equivalent to do:\n",
    "```\n",
    "qm_options[\"MAX_SCF_CYCLES\"] = 100\n",
    "qm_options[\"GEOM_OPT_MAX_CYCLES\"] = 80\n",
    "```\n",
    "In general, no matter the electronic structure code that is being used, the procedure to add extra options to the input is the same: `qm_options[\"option\"] = value`. To see the list of possible `options`, look at the documentation of the corresponding electronic structure code. In our case, we will use the following options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qchem_qm_options = {}\n",
    "qchem_qm_options[\"purecart\"] = \"1111\"\n",
    "qchem_qm_options[\"xc_grid\"] = \"000099000590\"\n",
    "qchem_qm_options[\"nl_grid\"] = \"1\"\n",
    "qchem_qm_options[\"unrestricted\"] = \"false\"\n",
    "qchem_qm_options[\"incdft\"] = \"0\"\n",
    "qchem_qm_options[\"incfock\"] = \"0\"\n",
    "qchem_qm_options[\"max_scf_cycles\"] = \"100\"\n",
    "qchem_qm_options[\"scf_guess\"] = \"sad\"\n",
    "qchem_qm_options[\"scf_convergence\"] = \"6\"\n",
    "qchem_qm_options[\"thresh\"] = \"11\"\n",
    "qchem_qm_options[\"symmetry\"] = \"false\" \n",
    "qchem_qm_options[\"sym_ignore\"] = \"true\"\n",
    "qchem_qm_options[\"geom_opt_max_cycles\"] = 80\n",
    "\n",
    "psi4_qm_options = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MB-Fit needs to know about the system we are dealing with, and the calculation details specified earlier. All this information is stored in a file with all these settings. For convenience, we generate this file *in situ*, and we describe below each one of the components that this file requires. We will refer to this file as `settings` file from now on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names of the different monomers present in the system is used to identify a given monomer in the database. They have no other purpose rather than identification. The name can have any length, and combine numbers and letters. It is not required but it is recommended to use capital letters only. The `names` variable is a list of strings that contains the monomers in the system:\n",
    "```\n",
    "names = [\"MON1\",\"MON2\",...]\n",
    "```\n",
    "After the definition of this list, the order of the monomers is set. If one has more than one monomer in that list, **monomer 1** will be the first element of the list, **monomer 2** the second one, and so on. When defining the properties of each monomer, this order will be important. In this first exampleit doesn't matter because there is only one monomer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"NH3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of atoms, spin, and charge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of atoms, charge of each monomer, and spin multiplicity of each monomer will be defined in the lists `number_of_atoms`, `charges`, and `spin`, respectively. These lists are lists of integers, and each element corresponds to the value of the list property of the monomer in that position (as defined in the list `names`.\n",
    "\n",
    "- `number_of_atoms` is the total number of atoms of the monomers. For example, CO$_2$ has 3 atoms, and NH$_3$ has 4. Any virtual site (either for the polynomials or for the electrostatics) should not be counted as \"atom\".\n",
    "- `charges` is the total charge of every monomer. Neutral monomers will have a charge of 0, while ions such as Cl$^-$ or NH$_4^+$ will have a charge of -1 and 1 respectively.\n",
    "- `spin` contains the spin multiplicities of the monomers, calculated as $M = 2S + 1$. For now, only closed shell systems are recommended since they have been throughly tested.\n",
    "\n",
    "If there is only one monomer, these variables still need to be a list, with a single element, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of atoms of each monomer\n",
    "number_of_atoms = [4]\n",
    "\n",
    "# Charge of each monomer\n",
    "charges = [0]\n",
    "\n",
    "# Spin multiplicity of each monomer\n",
    "spin = [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use MB-pol for monomer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously mentioned, MB-nrg and TTM-nrg are compatible with MB-pol by construction. When developing a two-body surface for a dimer in which one of the monomers is water, the partridge-shwenke dipole moment PEF should be used to describe the electrostatic properties of water in order to enable full compatibility with MB-pol. This can be passed to the MB-Fit library through the variable `use_mbpol`. If the value of this variable at the position `i` is 1, the monomer `i` will be assumed to be water, and the charges, polarizabilities, and polarizability factors will be calculated using the PS PEF. In this example, we just have ammonia, which is not water, and consequently, the variable `use_mbpol` will be a list of one element set to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_mbpol = [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Symmetry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commonly, in force fields, the interactions are described in a pairwise way and the different constants of the function describing an interaction depends on the atom types involved. The symmetry keyowrd in `MB-Fit` refers to the label that the atoms have. Each chemically unique atom will have a letter assigned, not related to their chemical identity. In order to build the symmetry, these are the steps to follow:\n",
    "1. Write the empirical formula of your molecule. As an example, for ammonia, is `NH3`\n",
    "2. Expand the chemical formula. This means that if there are two or more atoms that have a subindex, just repeat that atom. In the case of ammonia, we write `NHHH`\n",
    "3. Identify which atoms are chemically equivalent. This is very simple in small molecules, but can be complciated in larger molecules. To figure this out:\n",
    "   1. Locate two atoms that have the same atomic symbol. Two atoms that have different atomic symbols cannot be equivalent.\n",
    "   2. Replace one atom by `X` and look at the molecule.\n",
    "   3. Replace the other atom by `X` and compare this structure with the previous one. If the structure is the same, the two atoms are equivalent.\n",
    "4. Replace all the atomic symbols by letters, starting from `A`, and moving up in the alphabet (`B`,`C`...) using all capital letters. Each unique atom type must be represented by a different letter. In the case of ammonia, `NHHH` will become `ABBB`\n",
    "5. Compress the new label. There must be a number after each type, even if it is `1`. In the case of ammonia will be `A1B3`\n",
    "\n",
    "Then, the symmetry list can be defined as in below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symmetry = [\"A1B3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once symmetry is defined, the molecule symmetry can be obtained by joining all the elements in the symmetry list with an underscore `_`. We will refer to it as `molecule_in`. In the case of ammonia, symmetry and molecule in will be the same, with the exception that molecule in is a string and not a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecule_in_nh3 = \"_\".join(symmetry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMILES string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SMILES string is the way the connectivity of the molecule is passed into `MB-Fit`. In classical force fileds, the interactions between atoms are usually divided in bonded and non-bonded interactions. Typically, two atoms will be bonded if there are three or less bonds of distance between those two atoms, and non-bonded otherwise. When two atoms within the same molecule are non-bonded, the non-bonded interactions sucha as repulsion, dispersion and electrostatics are calculated, and ignored or scaled if the two atoms are bonded. The SMILES string will allow `MB-Fit` to find the connectivity matrix of the molecule.\n",
    "\n",
    "The SMILES string for each fragment must follow the [general rules](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system#Description) of SMILES strings in addition to the following extra rules:\n",
    "* Order of atoms in the SMILES string must match the order of the atoms in the XYZ file.\n",
    "* All hydrogen atoms must be included explicity.\n",
    "* Do not include any information about charges in your SMILES string.\n",
    "\n",
    "Writting a SMILES string by scratch might seem complicated, but these steps show how to do it in a simple way.\n",
    "1. Write out all atoms of the fragment in the same order they appear in your XYZ file. Remember, if any atom name is 2 letters, you must put square brackets around it.\n",
    "2. Add a '.' between any atoms that are not bonded.\n",
    "3. Add numbers after atoms to signify bonds between non-adjacent atoms. In the SMILES format you can bond two non-adjacent atoms by putting the same digit after them. For example, the SMILES string 'C1CC1' species a ring of 3 carbons. When there are multiple digits after a single atom each digit is treated independently. For instance, 'C12.C23.C31' also specifies a ring of 3 carbons. In this representation we have removed the implicit bond between adjacent atoms by adding a dot, and then introduced bonds between each pair of carbon atoms. If you need to specify more than 10 bonds you can use % signs to combine multiple digits: 'C%10%20.C%20%30.C%30%10' also specifies a ring of 3 carbons.\n",
    "\n",
    "Here is an example:\n",
    "\n",
    "Lets say our '.xyz' file for formaldehyde looks like this:\n",
    "```\n",
    "4\n",
    "comment line\n",
    "C   x   y   z\n",
    "O   x   y   z\n",
    "H   x   y   z\n",
    "H   x   y   z\n",
    "```\n",
    "\n",
    "Step 1) COHH\n",
    "Step 2) CO.H.H\n",
    "Step 3) C12O.H1.H2\n",
    "\n",
    "Here is another example:\n",
    "```\n",
    "3\n",
    "Chloroform\n",
    "C   x   y   z\n",
    "H   x   y   z\n",
    "Cl  x   y   z\n",
    "Cl  x   y   z\n",
    "Cl  x   y   z\n",
    "```\n",
    "\n",
    "Step 1) CH[Cl][Cl][Cl]\n",
    "Step 2) CH.[Cl].[Cl].[Cl]\n",
    "Step 3) C123H.[Cl]1.[Cl]2.[Cl]3\n",
    "\n",
    "In the case of ammonia, assuming that the XYZ is:\n",
    "```\n",
    "4\n",
    "comment line\n",
    "N   x   y   z\n",
    "H   x   y   z\n",
    "H   x   y   z\n",
    "H   x   y   z\n",
    "```\n",
    "\n",
    "Step 1) NHHH\n",
    "Step 2) NH.H.H\n",
    "Step 3) N12H.H1.H2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = [\"N12H.H1.H2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Electronic structure outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the electronic structure calculations outpus will be stored. The path where they will be put is defined in `log_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = \"logs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The SETTINGS file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The properties of the system, along with with some of the details for the electronic structure calculations, are stored in the `settings` file. This file is passed to the different methods in `MB-Fit` so the code can retrieve the information of the system. Below there is an example of the  settings file. Any line that starts with `#` will be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "[files]\n",
    "# Local path directory to write log files in\n",
    "log_path = logs\n",
    "\n",
    "[config_generator]\n",
    "# what library to use for geometry optimization and normal mode generation\n",
    "code = psi4\n",
    "# use geometric or linear progression for T and A in config generation, exactly 1 must be True\n",
    "geometric = False\n",
    "linear = False\n",
    "\n",
    "[energy_calculator]\n",
    "# what library to use for energy calculations\n",
    "code = psi4\n",
    "\n",
    "[psi4]\n",
    "# memory to use when doing a psi4 calculation\n",
    "memory = 4GB\n",
    "# number of threads to use when executing a psi4 calculation\n",
    "num_threads = 2\n",
    "\n",
    "[qchem]\n",
    "# number of threads to use when executing a qchem calculation\n",
    "num_threads = 2\n",
    "\n",
    "[molecule]\n",
    "# name of fragments, seperated by commas\n",
    "names = NH3\n",
    "# number of atoms in each fragment, seperated by commas\n",
    "fragments = 4\n",
    "# charge of each fragment, seperated by commas\n",
    "charges = 0\n",
    "# spin multiplicity of each fragment, seperated by commas\n",
    "spins = 1\n",
    "# tag when putting geometries into database\n",
    "tag = none\n",
    "# Use or not MB-pol\n",
    "use_mbpol = 0\n",
    "# symmetry of each fragment, seperated by commas\n",
    "symmetry = A1B3\n",
    "SMILES = N12H.H1.H2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user can write the file manually, or can use the following command to write the file with all the information inputed earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings for monomer\n",
    "settings_nh3 = \"settings_nh3_monomer.ini\"\n",
    "\n",
    "my_settings_file = \"\"\"\n",
    "[files]\n",
    "# Local path directory to write log files in\n",
    "log_path = \"\"\" + log_path + \"\"\"\n",
    "\n",
    "[config_generator]\n",
    "# what library to use for geometry optimization and normal mode generation\n",
    "code = \"\"\" + code + \"\"\"\n",
    "# use geometric or linear progression for T and A in config generation, exactly 1 must be True\n",
    "geometric = False\n",
    "linear = False\n",
    "\n",
    "[energy_calculator]\n",
    "# what library to use for energy calculations\n",
    "code = \"\"\" + code + \"\"\"\n",
    "\n",
    "[psi4]\n",
    "# memory to use when doing a psi4 calculation\n",
    "memory = \"\"\" + memory + \"\"\"\n",
    "# number of threads to use when executing a psi4 calculation\n",
    "num_threads = \"\"\" + str(num_threads) + \"\"\"\n",
    "\n",
    "[qchem]\n",
    "# number of threads to use when executing a qchem calculation\n",
    "num_threads = \"\"\" + str(num_threads) + \"\"\"\n",
    "\n",
    "[molecule]\n",
    "# name of fragments, seperated by commas\n",
    "names = \"\"\" + names[0] + \"\"\"\n",
    "# number of atoms in each fragment, seperated by commas\n",
    "fragments = \"\"\" + str(number_of_atoms[0]) + \"\"\"\n",
    "# charge of each fragment, seperated by commas\n",
    "charges = \"\"\" + str(charges[0]) + \"\"\"\n",
    "# spin multiplicity of each fragment, seperated by commas\n",
    "spins = \"\"\" + str(spin[0]) + \"\"\"\n",
    "# tag when putting geometries into database\n",
    "tag = none\n",
    "# Use or not MB-pol\n",
    "use_mbpol = \"\"\" + str(use_mbpol[0]) + \"\"\"\n",
    "# symmetry of each fragment, seperated by commas\n",
    "symmetry = \"\"\" + symmetry[0] + \"\"\"\n",
    "SMILES = \"\"\" + smiles[0] + \"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the file:\n",
    "ff = open(settings_nh3,'w')\n",
    "ff.write(my_settings_file)\n",
    "ff.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The permutationally invariant polynomials can be generated using `MB-Fit`. The first step is to define all the variables that will be involved in the polynomials. They can be obtained by calling the `generate_poly_input` function, which usage is the following, and it generates a file that lists all the different variables that can be in the polynomial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "generate_poly_input(settings_path, molecule_in, in_file_path, virtual_sites=['X', 'Y', 'Z'])\n",
    "    Generates an input file for polynomial generation.\n",
    "    \n",
    "    Args:\n",
    "        settings_path       - Local path to the file containing all relevent settings information.\n",
    "        molecule_in         - String idicating symmetry of molecule, ie \"A1B2_A1B2\" for (CO2)2\n",
    "        in_file_path        - Local path to the file to write the polynomial input to.\n",
    "        virtual_sites       - List of Symmetry labels that are virtual sites.\n",
    "                Default: [\"X\", \"Y\", \"Z\"]\n",
    "    \n",
    "    Returns:\n",
    "        None.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function requires the settings file, previously defined and explained. It also requires the molecule symmetry, which as mentioned earlier, has been defined in `molecule_in`. The argument `in_file_path` will contain the name of the file that will be generated with all the information. The optional argument `virtual_sites` specifies which letters will represent virtual sites in the molecules. Currently, `MB-fit` only accepts virtual sites for `MB-pol` water, and will be described later in the manual. Before generating the polynomial input file, let's define the name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_in_nh3 = \"poly_nh3.in\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point the polynomial generation input with all the variables can be generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mbfit.generate_poly_input(settings_nh3, molecule_in_nh3, poly_in_nh3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file generated should be like this:\n",
    "```\n",
    "add_molecule['A1B3']\n",
    "\n",
    "add_variable['A', '1', 'a', 'B', '1', 'a', 'x-intra-A+B-1']\n",
    "add_variable['A', '1', 'a', 'B', '2', 'a', 'x-intra-A+B-1']\n",
    "add_variable['A', '1', 'a', 'B', '3', 'a', 'x-intra-A+B-1']\n",
    "add_variable['B', '1', 'a', 'B', '2', 'a', 'x-intra-B+B-1']\n",
    "add_variable['B', '1', 'a', 'B', '3', 'a', 'x-intra-B+B-1']\n",
    "add_variable['B', '2', 'a', 'B', '3', 'a', 'x-intra-B+B-1']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two keywords in the generated file. The first one, `add_molecule` states that a new molecule is added to the system. The second one, `add_variable`, specifies that a variable $\\xi _{ij}$ that depends on the distance between atoms $i$ and $j$ will be added to the system. Concretely,\n",
    "```\n",
    "add_variable['A', '1', 'a', 'B', '2', 'a', 'x-intra-A+B-1']\n",
    "```\n",
    "translates into add a variable between the first atom of type `A` from the first monomer (`a`) `['A', '1', 'a']` and the second atom of type `B` of the first monomer (`a`) `['B', '2', 'a']`, which non-linear parameter constant will have the tag `x-intra-A+B-1`. Variables with the same constant tag will have the same non-linear parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user is free to remove any variable that is not wanted in the polynomial expression, but the use of all the variables and the addition of filters is the recommended option. When the molecule grows in size and the polynomial maximum order increases, the number of terms that the polynomial has increases exponentially. Typically, the number of terms in the polynomial should not exceed 2000, and this number is easily exceeded for larger systems. In these situations, the best solution is to apply filters. An extended explanation of the filter format and their options can be found in the `FILTERS.md` file inside `MBFIT_HOME/docs`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the input and the filters have been decided, the polynomial generation function `generate_polynomials` can be called:\n",
    "```\n",
    "generate_polynomials(settings_path, poly_in_path, order, poly_dir_path, generate_direct_gradients=True, num_gradient_terms_per_line=1)\n",
    "    Generates polynomial input for maple and some \".cpp\" and \".h\" polynomial files.\n",
    "    \n",
    "    Args:\n",
    "        settings_path       - Local path to the file containing all relevent settings information.\n",
    "        poly_in_path        - Local path to the file to read the polynomial input from. Name of file should be in\n",
    "                the format \"A1B2.in\". It is ok to have extra directories prior to file name. For example:\n",
    "                \"thisplace/thatplace/A3.in\".\n",
    "        order               - The order of the polynomial to generate.\n",
    "        poly_dir_path       - Local path to the directory to write the polynomial files in.\n",
    "        generate_direct_gradients - If True, then a gradients cpp file is generate additionally to the polynomial\n",
    "                cpp file. This may take a while.\n",
    "                defualt: False.\n",
    "        num_gradient_terms_per_line - The number of terms to put in each line in the cpp file\n",
    "                for computing the gradients. Larger numbers may result in slower compilation times.\n",
    "    \n",
    "    Returns:\n",
    "        None.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`settings_path` is the settings file. Since it was generated in the working directory, the name of the file will be enough, and has been defined earlier under the variable `settings_nh3`; same with the `poly_in_path`. The maximum order that the polynomial will have is set by `order`. Given a triatomic molecule `B--A--B`, there are three distances: between atoms A and B$_1$, which we call $\\vec{r}_{AB_1}$; between atoms A and B$_2$ ($\\vec{r}_{AB_2}$); and between atoms B$_1$ and B$_2$ ($\\vec{r}_{B_1B_2}$). Consequently, there are three possible variables that can be used to generate the polynomials: $\\xi _{AB_1}$, $\\xi _{AB_2}$, and $\\xi _{B_1B_2}$. Note that at this point the functional form of $\\xi$ is still irrelevant, but it is a function of the distance between the two atoms involved. With this three variablesthe following polynomial can be written:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "P(\\xi _{AB_1},\\xi _{AB_2},\\xi _{B_1B_2}) &=  K_1\\xi _{AB_1} + K_2\\xi _{AB_2} + K_3\\xi _{B_1B_2} \\leftarrow \\text{Degree 1} \\\\\n",
    "&+ K_4\\xi _{AB_1}\\xi _{AB_1} + K_5\\xi _{AB_2}\\xi _{AB_2} + K_6\\xi _{B_1B_2}\\xi _{B_1B_2} + K_7\\xi _{AB_1}\\xi _{AB_2} + K_8\\xi _{AB_1}\\xi _{B_1B_2} + K_9\\xi _{AB_2}\\xi _{B_1B_2} \\leftarrow \\text{Degree 2} \\\\\n",
    "&+ K_{10}\\xi _{AB_1}\\xi _{AB_1}\\xi _{AB_1} + ... \\leftarrow \\text{Degree 3}\n",
    "\\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(\\xi _{AB_1},\\xi _{AB_2},\\xi _{B_1B_2})$ can be written up to any degree, but the higher the degree, the higher the number of terms. For a given molecule, several orders should be tested and use a maximum polynomial degree $n$ that keeps the number of linear terms $K_i\\xi_1 ^{a_1} ... \\xi _k ^{a_k}$, with $\\sum _{j=1} ^ k a_j \\leq n$, lower than 2000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_order_nh3 = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have been talking about permutationally invariant polynomials, but the polynomial above is not permutationally invariant. Specifically, let's look at the first degree terms $K_1\\xi _{AB_1}$ and $K_2\\xi _{AB_2}$. $\\xi _{AB_1}$ refers to the distance between A and the **first** B atom, while $\\xi _{AB_2}$ refers to the distance between A and the **second** B atom. However, both variables $\\xi _{AB_1}$ and $\\xi _{AB_2}$ should have the same constant parameters since both are describing the same exact distance type. If the constants $K_1$ and $K_2$ are different, changing the order of the B aoms would change the value of the polynomial evaluation, and physically, this is not correct, since no matter which order do the B atoms have, the molecule AB2 is exactly the same. The symmetrization process, which is also performed in the generation of the polynomials, fixes this issue. Instead of having two terms $K_1\\xi _{AB_1}$ and $K_2\\xi _{AB_2}$, the algorithm will symetrize them into $K_{\\alpha}(\\xi _{AB_1} + \\xi _{AB_2})$. With this new term it doesnt matter which atom B is B$_1$ or B$_2$, and it will always evaluate to the same value no matter the order of identical atoms. This process is performed for all the terms that can be symmetrized, reducing the number of linear constants $K$ that will need to be fitted, and ensuring the permutationally invariance of the polynomials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `generate_polynomials` function can aso generate the analytical gradients of the polynomials. However, for fitting purposes, the gradients are not used. These files will be required by `MBX` in order to run molecular dynamics simulations or other calculations that require the gradients. If thegradients are generated, depending on the size of the molecule and the degree, each one of the variable gradients can have hundreds or thousands of terms. Compilation time in these situations becomes extremely slow, and can be improved with a payback on the runtime speed by splitting the calculation of each variable gradient. The number of terms per group is controlled by the `num_gradient_terms_per_line` argument. Since the purpose of this manual is to show document the fitting part, the gradients won't be generated. All the polynomial files will be generated and added to the folder defined in `poly_in_path`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_directory_nh3 = \"polynomials_files_directory_nh3_monomer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.generate_polynomials(settings_nh3, poly_in_nh3, polynomial_order_nh3, polynomial_directory_nh3, \n",
    "                           generate_direct_gradients=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several files should have been generated in the folder `polynomial_directory_nh3`:\n",
    "- `poly.log` contains the information about how many variables, permutations, and terms for each degree the polynomial has, including the total number of terms and the filtered terms. The total number of terms at the end of that file is the number of $K_i\\xi_1 ^{a_1} ... \\xi _k ^{a_k}$ terms that the polynomial will have. If this number is larger than 2000, some filtering should be added, or the maximum degree should be decreased. Physical intuition should be used when adding filters. As an example, if a given degree $n$ yields too many terms, filtering the terms that contain a high degree of a variable involving two atoms which interaction is very small, such as two hydrogen atoms, is a good strategy. This reduces the number of terms and maintains the flexibility of the polynomial.\n",
    "- `vars.cpp` is a file that summarizes the variables involved in the polynomial. This file is not used by the user and contains the same information as the polynomial input file.\n",
    "- `poly-direct.cpp` is a C++ function that given the linear coefficients $K_i$ and the variables $\\xi _j$ will return the evaluation of the polynomial at that point. A `poly-direct-grd.cpp` file will be generated if the gradients have been calculated. This file will return the same value as the `poly-direct.cpp` file in addition to the gradients of each one of the derivatives. Summarizing, given $\\vec{K} = [K_1, K_2, ..., K_M]$ and $\\vec{\\xi} = [\\xi _1,\\xi _2, ..., \\xi _N]$, where $M$ is the number of terms and $N$ is the number of variables, `poly-direct.cpp` will return $V_{poly}$, and `poly-direct-grd.cpp` will return the same $V_{poly}$ and the gradients $\\nabla P(\\xi _1, ... , \\xi _N) = \\lbrack \\frac{\\partial P}{\\xi _1},..., \\frac{\\partial P}{\\xi _N} \\rbrack$. The `poly-model.h` file is the header file for both gradient and no-gradient files.\n",
    "- `poly-nogrd.maple` and  `poly-grd.maple` are files that are automatically generated no matter the options in the polynomials. The polynomial evaluations in the direct form is slow, and if the user has MAPLE, the function `execute_maple` can be used to optimize the evaluation of the polynomials. This step will generate optimized evaluations for the polynomials with and without gradients. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "execute_maple(settings_path, poly_dir_path)\n",
    "    Runs maple on the polynomial files in the specified directory to turn them into actual cpp files.\n",
    "    \n",
    "    Args:\n",
    "        settings_path       - Local path to the file containing all relevent settings information.\n",
    "        poly_directory      - Local path to the directory to read the \".maple\" files from and write the \".cpp\" files\n",
    "                to.\n",
    "    \n",
    "    Returns:\n",
    "        None.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two arguments of this function have been previously described, and it will generate two extra useful files to be used for the energy evaluation function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.execute_maple(settings_nh3, polynomial_directory_nh3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the previous command has been executed, two extra files conaining the optimized evaluation of the polynomial function with and without gradients have been generated, being `poly-grd.cpp` and `poly-nogrd.cpp` those files. **Maybe talk about optimization...?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set and test set generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In any machine learning scheme, the goal is to be able to predict the outcome of an event by using knowledge of events in which the outcome is known. In the case of energy, the goal is to predict the energy of a molecular system given the coordinates of all the atoms. We need to train the model with configurations for which the energy is known. These set of configurations will be the **training set**. To assess that the model actually predicts the right energies, we will also need a set of configurations for which the energy is known, but that will not be included in the training set. This set of configurations will be called the **test set**. Usually we will assess the accuracy of a fit by calculating the root mean square deviation (RMSD) of the training and test sets. Ideally, both sets should have a low RMSD and of a cimilar order of magnitude. To calculate the RMSD, the following expression is used:\n",
    "$$\\text{RMSD} = \\sqrt{\\frac{\\sum _{i=1} ^N (y_i^{calc} - y_i^{ref})^2}{N}}$$\n",
    "where $N$ is the number of data points, $y_i^{calc}$ is the value of the predicted energy, and $y_i^{ref}$ is the reference energy of that same configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The degree of the polynomial and the size of the training set must be carefully selected to avoid underfitting and overfitting. Underfitting occurs when the function used as model is not flexible enough to reproduce the reference data. An example of underfitting is found on the left panel in the figure below. The model used is a straight line, and it is trying to reproduce a curve with not much success. Although this is a problem in terms of accuracy of the model, it usually does not represent a problem in its stability. However, when the model has too many parameters in comparison with the number of points in the training set, overfitting can occur. The fit will have an apparent excellent agreement with the reference data, but the test set will probably have a bad agreement with the model. When the RMSD of the training set is small, but the one for the test set is large, overfitting is most likely happening and we need to either increase the size of our training set, or decrease the number of terms. When overfitting occurs, there is a big chance of finding **holes** in the PEF, which means that the models does not have information in a region of the space, and the energy that is predicted is usually largely negative, as it is shown in the right pannel of the figure below. Ideally, the wanted behavior is the one shown in the central pannel, in which the model behaves properly within the range of the sample points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/over_underfitting.png\" alt=\"overunderfitting\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recommend to have a training set with a number of configurations that is 20 times the number of linear terms in the polynomials, with a minimum of 500 configurations, and use a 20% of that number for the test set. We first need to define the names of the training and the test sets. First we will generate the configurations, and then we will generate the formatted training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XYZ file with the configurations of the training set\n",
    "training_configs_nh3 = \"training_configs_nh3.xyz\"\n",
    "\n",
    "# XYZ file with the configurations of the test set\n",
    "test_configs_nh3 = \"test_configs_nh3.xyz\"\n",
    "\n",
    "# XYZ file with the training set that the codes need to perform the fit\n",
    "# Configurations are the same as training_configs but this file\n",
    "# has the energies in the comment line\n",
    "training_set_nh3 = \"training_set_nh3.xyz\"\n",
    "\n",
    "# XYZ file with the test set that the codes need to perform the fit\n",
    "# Configurations are the same as test_configs but this file\n",
    "# has the energies in the comment line \n",
    "test_set_nh3 = \"test_set_nh3.xyz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the definition of the filenames that will contain the training and test configurations and formatted sets, we have to specify the details of the training set. The number of configuration will be the first point to tackle. As mentioned, it should be at least 20 times the number of terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of configurations in the 1b training_set\n",
    "num_training_configs = 500\n",
    "\n",
    "# Number of configurations in the 1b test set\n",
    "num_test_configs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set and the test set must contain configurations around the minimum energy structure (the configuration with the lowest energy). However, distorted configurations must also appear to avoid extrapolationg values for the polynomials. The average energy, following a Boltzman distribution, in a molecular dynamics simulation at room temperature is 0.593 kcal/mol. Technically, having distortions up to 0.6 kcal/mol should be enough to have a stable simulation at room temperature. However, 0.593 kcal/mol is the average energy that a molecule will have, and does not mean that a higher values are not possible. There might be instantaneous fluctuations in which the molecule is distorted several kcal/mol, and if those configurations are not sampled in the training set, the PEF will have a hole, giving a non-physical value for the energy. The recomendation is to use a maximum distortion energy ($E_i ^{dist} = E_i -E_i ^{min}$) of 100 kcal/mol. This will ensure that the configurational space that can be visited up to several hundreds Kelvin is represented in the training and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum energy allowed for distorted monomers (in kcal/mol)\n",
    "maximum_1b_energy = 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of the formatted training set is nothing else than a single XYZ file with all the configurations, one after the other one, with two numbers in the comment line, which are, in this order, the binding energy and the n-body energy. In this first ammonia example, the n-body energy is the one-body energy. The different orders of the many-body energies have been introduced earlier. However, the concept binding energy (BE) appears here for the first time. There are multiple definitions on how to calculate the BE, but the simplest way is:\n",
    "$$ \\text{BE} = E^{tot} - \\sum _{i=1} ^N E_i ^{opt}$$\n",
    "where $E^{tot}$ is the total energy of the system, $N$ is the total number of monomers in the system, and $E_i^{opt}$ is the optimized energy of monomer $i$. If we work out the equation for one-body, we conclude that for this case, the binding energy and the distorsion energy are the same.\n",
    "$$ \\text{BE} = E^{tot} - E_1 ^{opt} = E ^{dist}$$\n",
    "Thus, the maximum binding energy will be set to be the same as the maximum distortion energy (or also one-body energy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_binding_energy = maximum_1b_energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set and the test set will both be generated, in the case of the one-body PEF, using normal mode samplig. To do so, the first step is to optimize the molecule and calculate the normal modes. We first need to define a structure that is close the the minimum energy structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XYZ file that contains the unoptimized geommetry of monomer 1\n",
    "unoptimized_nh3 = \"nh3.xyz\"\n",
    "\n",
    "my_unopt_monomer = \"\"\"4\n",
    "unoptimized nh3\n",
    " N                 -0.79953653    0.30706836    0.00000000\n",
    " H                 -0.46621464   -0.63574472    0.00000000\n",
    " H                 -0.46619743    0.77846854    0.81649673\n",
    " H                 -0.46619743    0.77846854   -0.81649673\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the file:\n",
    "ff = open(unoptimized_nh3,'w')\n",
    "ff.write(my_unopt_monomer)\n",
    "ff.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The XYZ file where the optimized monomer structure will be sotred has to be defined too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_nh3 = \"nh3_opt.xyz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to perform the optimization. The function `optimize_geometry` will take care of that. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "optimize_geometry(settings_path, unopt_geo_path, opt_geo_path, method, basis, qm_options={})\n",
    "    Optimizes the geometry of the given molecule.\n",
    "    \n",
    "    Args:\n",
    "        settings_path       - Local path to the file containing all relevent settings information.\n",
    "        unopt_geo_path      - Local path to the file to read the unoptimized geoemtry from.\n",
    "        opt_geo_path        - Local path to the file to write the optimized geometry to.\n",
    "        method              - The method to use for this geometry optimization.\n",
    "        basis               - The basis to use for this geometry optimization.\n",
    "        qm_options           - Dictionary of extra arguments to be passed to the QM code doing the calculation.\n",
    "    \n",
    "    Returns:\n",
    "        None.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the arguments of this function have been previously defined. After the call, a new file with the optimized geometry will have appeared in the working directory. This function will use the electronic structure method defined in `method` with the basis set defined in `basis`, to optimize the geometry in the file defined by `unoptimized_nh3`, and save the result in the file defined by `optimized_nh3` using the options defined in `qm_options`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.optimize_geometry(settings_nh3, unoptimized_nh3, optimized_nh3, method, basis, qchem_qm_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the optimized structure has been obtained, it can be used to calculate the normal modes with the `generate_normal_modes` function, which will perform a normal mode calculation using the software, method and basis set specified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "generate_normal_modes(settings_path, opt_geo_path, normal_modes_path, method, basis, qm_options={})\n",
    "    Generates the normal modes for the given molecule.\n",
    "    \n",
    "    Args:\n",
    "        settings_path       - Local path to the file containing all relevent settings information.\n",
    "        opt_geo_path        - Local path to the file to read the optimized geometry from.\n",
    "        normal_modes_path   - Local path to the file to write the normal modes to.\n",
    "        method              - The method to use for this normal modes calculation.\n",
    "        basis               - The basis to use for this normal modes calculation.\n",
    "        qm_options           - Dictionary of extra arguments to be passed to the QM code doing the calculation.\n",
    "    \n",
    "    Returns:\n",
    "        Null dimension of normal modes.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normals modes will be calculated, and their frequencies and displacement vectors will be stored in the formatted file `normal_modes_path`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_modes_nh3 = \"normal_modes_nh3.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.generate_normal_modes(settings_nh3, optimized_nh3, normal_modes_nh3, method, basis, qchem_qm_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation of the normal mode generation training set.**\n",
    "- Explain the method\n",
    "- explain the different distributions (A dist vs T dist (What is A? do we need it?), classical, quantum,..)\n",
    "- explain the default splittting of the temperatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the methodology previously describe, we can generate configurations using the function `generate_normal_mode_configurations`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "generate_normal_mode_configurations(settings_path, opt_geo_path, normal_modes_path, configurations_path, number_of_configs=100, seed=None, classical=True, distribution='piecewise', temperature=None, distribution_function=None)\n",
    "    Generates normal mode configurations for a given molecule from a set of normal modes.\n",
    "    \n",
    "    If both linear and geometric are False, will use a piecewise distribution over temperature.\n",
    "    \n",
    "    Args:\n",
    "        settings_path       - Local path to the file containing all relevent settings information.\n",
    "        opt_geo_path        - Local path to the file to read optimized geometry from.\n",
    "        normal_modes_path   - Local path to the file to read normal modes from.\n",
    "        dim_null            - The null dimension of this molecule, see generate_normal_modes().\n",
    "        config_path         - Local path to the file to write configurations to.\n",
    "        number_of_configs   - Number of configurations to generate\n",
    "        seed                - The same seed with the same molecule and normal modes will always generate the same\n",
    "                configurations.\n",
    "        classical           - If True, use a classical distribution over temp and A, otherwise, use a quantum\n",
    "                distribution. QM distributions generate a wider distribution over energy.\n",
    "                Default: True\n",
    "        distribution        - One of the following choices: 'piecewise', 'constant', 'linear', 'geometric', 'custom'\n",
    "                'piecewise' uses a piecewise distribution in the following style:\n",
    "                    5% at highest frequency / 100\n",
    "                    40% at highest frequency / 20\n",
    "                    30% at highest frequency / 10\n",
    "                    20% at highest frequency / 5\n",
    "                    5% at highest frequency / 2\n",
    "                'constant' uses a set temperature for all configurations.\n",
    "                    Specify the temperature by setting the temperature argument to a single value.\n",
    "                'linear' uses a linear distribution from a minimum to a maximum temperature.\n",
    "                    Specify the min and max temperature by setting the temperature argument to a 2-tuple: (min, max).\n",
    "                    If temperature is unspecified, then the minimum is 0, and the maximum is the highest normal mode frequency.\n",
    "                'geometric' uses a geometric distribution from a minimum to a maximum temperature.\n",
    "                    Specify the min and max temperature by setting the temperature argument to a 2-tuple: (min, max).\n",
    "                    If temperature is unspecified, then the minimum is 0, and the maximum is the highest normal mode frequency.\n",
    "                'custom' uses a user-specified DistributionFunction to generate the temperatures used during configuration generation.\n",
    "        temperature         - Should be set to different values based on what distribution is being used.\n",
    "                If 'piecewise' or 'custom' distribution, then temperature is ignored.\n",
    "                If 'constant' distribution, then temperature should be a single value.\n",
    "                If 'linear' or 'geometric' distribution, then temperature should be a 2-tuple: (min, max)\n",
    "                All temperatures should be specified in KELVIN.\n",
    "        distribution_function - Implementation of DistributionFunction. Only used if distribution='custom'.\n",
    "                distribution_function.get_vale(x) should be implemented over the domain [0,1]. So the first config\n",
    "                will have temperature = distribution_function.get_value(0) and the last config will have temperature =\n",
    "                distribution_function.get_value(1), with configurations in between passing linearly increasing values to \n",
    "                distribution_function.get_value(x).\n",
    "                The distribution_function should return temperatures in atomic units (NOT KELVIN).\n",
    "                See package utils.distribution_function for abstract DistributionFunction class and example implementaitons.\n",
    "    \n",
    "    Returns:\n",
    "        None.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this function, some of the arguments have already been seen. The configurations that will be generated are going to be stored in the file defined by `config_path`, previoulsy defined as `training_configs_nh3` and `test_configs_nh3`, and will generate as many configurations as `number_of_configs` indicates. \n",
    "\n",
    "The selection of the normal mode coordinates will be given by random numbers. As in any random number generator, it needs a seed. If no seed is given to the functions that use random numbers, the machine time will be taken as seed, which ensures different results every time that the fnction is run. The recomendation is to use a defined seed for every function call, to ensure reproducibility of the results. However, the seeds for different sets of the training or test set must be different, or exactly the same configurations will be generated. The seed must be an integer within the python integer range:\n",
    "\n",
    "($2^{31} - 1$,$-(2^{31}) - 2$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_training = 12345\n",
    "seed_test = 54321"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can define the temperature (in Kelvin) at which the normal modes will be sampled. If undefined, the piecewise distribution of temperatures will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using or not a classical distribution is the user's choice. Classical distributions will result in narrower distributions, but at high temperature of sampling, the classical and the quantum distribution will become more similar. In this example, the classical distribution will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classical = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the options have been defined, and the training and test set configurations can be now generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set\n",
    "mbfit.generate_normal_mode_configurations(settings_nh3, optimized_nh3, normal_modes_nh3, \n",
    "                                          training_configs_nh3, number_of_configs=num_training_configs, \n",
    "                                          seed=seed_training, classical=classical)\n",
    "\n",
    "#Test Set\n",
    "mbfit.generate_normal_mode_configurations(settings_nh3, optimized_nh3, normal_modes_nh3, \n",
    "                                          test_configs_nh3, number_of_configs=num_test_configs, \n",
    "                                          seed=seed_test, classical=classical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Electronic Structure Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the configurations generated, the next step is to calculate the energy of each one of them. `MB-Fit` provides with an infrastructure based on POSTGRE database. \n",
    "\n",
    "**Maybe add some info about what to do and how to install**\n",
    "\n",
    "After set up and installation of the database, the information to access it must be written in a file. Any function that performs operations on the database, either writting or reading information, needs a `database.ini` file with the information about the host, the port, the database name, the username, and the password. The format of this file is similar to the `settings` file:\n",
    "\n",
    "```\n",
    "[database]\n",
    "host = host.name.edu\n",
    "port = 5432\n",
    "database = my_database\n",
    "username = my_username\n",
    "password = my_password\n",
    "```\n",
    "\n",
    "The file is created below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_settings = \"database.ini\"\n",
    "my_database_settings = \"\"\"[database]\n",
    "host = piggy.pl.ucsd.edu\n",
    "port = 5432\n",
    "database = potential_fitting\n",
    "username = potential_fitting\n",
    "password = 9t8ARDuN2Wy49VtMOrcJyHtOzyKhkiId\n",
    "\"\"\"\n",
    "\n",
    "# Write the file. Remember to update the username and password!\n",
    "ff = open(database_settings,'w')\n",
    "ff.write(my_database_settings)\n",
    "ff.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the database is set up, the configurations generated for the test and for the training set can be added with the function `init_database`. This will add all the configurations of a given XYZ file to the database. If the configuration is already there and it has the same tag, it won't add it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "init_database(settings_path, database_config_path, configurations_path, method, basis, cp, *tags, optimized=False)\n",
    "    Creates a database from the given configuration .xyz files. Can be called on a new database\n",
    "    to create a new database, or an existing database to add more energies to be calculated\n",
    "    \n",
    "    Args:\n",
    "        settings_path       - Local path to the file containing all relevent settings information.\n",
    "        database_config_path - .ini file containing host, port, database, username, and password.\n",
    "                    Make sure only you have access to this file or your password will be compromised!\n",
    "        configurations_path - Local path to a single .xyz file.\n",
    "        method              - QM method to use to calculate the energy of these configurations.\n",
    "        basis               - QM basis to use to calculate the energy of these configurations.\n",
    "        cp                  - Use counterpoise correction for these configurations?\n",
    "        tags                - Mark the new configurations with these tags.\n",
    "        optimized           - Are these configurations optimized geometries? Defualt is False.\n",
    "    \n",
    "    Returns:\n",
    "        None.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`settings_path` is the path to the settings file as usual, and `database_config_path` is the file that contains the database access information. `configurations_path` is the XYZ file that contains the configuration(s) that need to be added to the database. Each file needs to be added in a different function call. `method` and `basis` are the electronic structure method and basis set that will be used to calculate the energies of the configurations added. When using small basis sets, and even large basis sets that are not close to the complete basis set limit, it is recomended to use counter-poise correction to correct for the basis set superposition error (BSSE). This option can be activated by setting `cp` to `True`. This correction only takes effect if there is more than one monomer, so for the one-body calculations can be set to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After these mandatory arguments, the `tags` are needed. The function of the tags is to differenciate molecules that are the same but belong to multiple sets. In this simple example, there are two sets that should have excluding geometries, i.e. a geometry in the training set should not be present in the test set and viceversa. Two tags will be used: `\"training_nh3\"` for the training set and `\"test_nh3\"` for the test set. Finally, the `optimized` argument indicates if the configurations added are optimized (the minimum energy structure) or not, and can be set to `True` or `False`. The optimized geommetry must always be in any set, since is used to calculate the binding energy required to generate the formatted training sets. To add the configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add training set configurations\n",
    "mbfit.init_database(settings_nh3, database_settings, training_configs_nh3, method, basis, cp, \"training_nh3\", optimized = False)\n",
    "\n",
    "# Add test set configurations\n",
    "mbfit.init_database(settings_nh3, database_settings, test_configs_nh3, method, basis, cp, \"test_nh3\", optimized = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the optimized monomer to both tags\n",
    "mbfit.init_database(settings_nh3, database_settings, optimized_nh3, method, basis, cp, \"training_nh3\", \"test_nh3\", optimized = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The configurations are now in the database ready to be computed. The set of electronic structure calculations can be computed simply by calling the `fill_database` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "fill_database(settings_path, database_config_path, client_name, *tags, calculation_count=9223372036854775807, qm_options={})\n",
    "    Goes through all the uncalculated energies in a database and calculates them. Will take a while. May be interrupted\n",
    "    and restarted.\n",
    "    \n",
    "    Args:\n",
    "        settings_path       - Local path to the file containing all relevant settings information.\n",
    "        database_config_path - .ini file containing host, port, database, username, and password.\n",
    "                    Make sure only you have access to this file or your password will be compromised!\n",
    "        client_name         - Name of the client performing these calculations.\n",
    "        tags                - Only perform calculations marked with at least one of these tags.\n",
    "        calculation_count   - Maximum number of calculations to perform. Unlimited if None.\n",
    "        qm_options           - Dictionary of extra arguments to be passed to the QM code doing the calculation.\n",
    "    \n",
    "    Returns:\n",
    "        None.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will loop over all the jobs in the database corresponding associated with the tags passed as argument, and will run the ones in pending state. The mandatory argument `client_name` is the name of the client using the database. We can call it `TheManual`. The optional argment `calculation_count` specifies the maximum number of calculations that will be run, being the default practically unlimited. All the other arguments have been described in previous calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_name = \"TheManual\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.fill_database(settings_nh3, database_settings, client_name, \"training_nh3\", \"test_nh3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option to fill the database with the energies is to use the job maker and the job reader. If a supercomputer is available, it might be convenient to write python scripts that will execute each calculation separately. Then, on the supercomputer one can just loop and submit each job separetly. First, we must use the `make_jobs` function to generate the python scripts, that will be stored in the `jobs_folder`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_folder = \"jobs\"\n",
    "mbfit.make_jobs(settings_nh3, database_settings, \n",
    "                            client_name,jobs_folder, \n",
    "                            \"training_nh3\", \"test_nh3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the job scripts have been generated, they can be run externally. An example is shown below, but possibilities are limitless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the jobs (can be done externally, supercomputer...)\n",
    "import glob\n",
    "\n",
    "# Check if jobs folder exists\n",
    "if os.path.isdir(jobs_folder):\n",
    "    os.chdir(jobs_folder)\n",
    "    \n",
    "    # Look for all the files that are a python script in that folder\n",
    "    job_files = glob.glob('*.py')\n",
    "    njobs = 0\n",
    "    # Run each job\n",
    "    for this_job in job_files:\n",
    "        njobs += 1\n",
    "        print(njobs,\"/\",len(job_files))\n",
    "        os.system(\"python3 \" + this_job)\n",
    "    os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, after all the jobs have been completed, the call to the `read_jobs` function must be made to add all the information inside the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the job outputs and store information in the database\n",
    "if os.path.isdir(jobs_folder):\n",
    "    mbfit.read_jobs(settings_nh3, database_settings, jobs_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all the configurations already in the database, the final step of the training set generation is to create the formatted training and test sets files. The training set and the test set are expected to be in XYZ format with the binding energy and the n-body energy, in this order, in the comment line. Distances are expected to be in Angstrom, and energies in kcal/mol:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "<number of atoms>\n",
    "<Binding Energy (kcal/mol)> <N-body Energy (kcal/mol)>\n",
    "At1   At1x   At1y   At1z\n",
    "At2   At2x   At2y   At2z\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set can be automatically generated if the electronic structure calculations have been put in the database. Otherwise, one needs to generate it manually. In order to retrieve it from the database, the function `generate_training_set` must be called:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "generate_training_set(settings_path, database_config_path, training_set_path, method, basis, cp, *tags, e_bind_min=-inf, e_bind_max=inf, e_mon_min=-inf, e_mon_max=inf, deprecated_fitcode=False)\n",
    "    \"\n",
    "    Creates a training set file from the calculated energies in a database.\n",
    "    \n",
    "    Args:\n",
    "        settings_path       - Local path to the \".ini\" file with all relevent settings information.\n",
    "        database_config_path - .ini file containing host, port, database, username, and password.\n",
    "                    Make sure only you have access to this file or your password will be compromised!\n",
    "        training_set_path   - Local path to file to write training set to.\n",
    "        method              - Use energies calculated with this method. Use % for any method.\n",
    "        basis               - Use energies calculated with this basis. Use % for any basis.\n",
    "        cp                  - Use energies calculated with this cp. Use 0 for False, 1 for True, or % for any cp.\n",
    "        tags                - Use energies marked with at least one of these tags. Use % for any tag.\n",
    "        e_bind_min          - Minimum binding energy allowed, inclusive.\n",
    "        e_bind_max          - Maximum binding energy allowed, exclusive.\n",
    "        e_mon_max           - Minimum monomer deformation energy allowed, inclusive.\n",
    "        e_mon_max           - Maximum monomer deformation energy allowed, exclusive.\n",
    "        deprecated_fitcode  - Is this function being called to be used with the deprecated fitcode?\n",
    "                The output of the 1b and 2b training sets will be different.\n",
    "    \n",
    "    Return:\n",
    "        None.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new mandatory argument `training_set_path` is the path to the file where the training set (or test set) will be written. The optional arguments `e_bind_min` and `e_bind_max` are the minimum and maximum binding energy allowed for configuration in the training set. One typically wants to include high energy configurations but no more than 100-150 kcal/mol. Otherwise, although weights are used in the fitting procedure, these configurations might make the low energy region slightly less accurate. The optional arguments `e_mon_min` and `e_mon_max` determine the minimum and maximum distortion energy allowed for a monomer. It is recommended not to have distortions higher than 40 kcal/mol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = \"nh3_monomer_training_set.xyz\"\n",
    "test_set = \"nh3_monomer_test_set.xyz\"\n",
    "e_bind_max = 150.0\n",
    "e_mon_max = 30.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the training set\n",
    "mbfit.generate_training_set(settings_nh3,database_settings,training_set,method,basis,cp,\n",
    "                            \"training_nh3\",e_bind_max = e_bind_max,e_mon_max = e_mon_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the test set\n",
    "mbfit.generate_training_set(settings_nh3,database_settings,test_set,method,basis,cp,\n",
    "                            \"test_nh3\",e_bind_max = e_bind_max,e_mon_max = e_mon_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate system properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total n-body energy of a system can be decomposed in different contributions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$V^{nb} = V_{poly}^{nb} + V_{rep}^{nb} + V_{disp}^{nb} + V_{elec}^{nb}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $V_{rep}^{nb}$ is the short range (or repulsive) energy, $V_{disp}^{nb}$ is the dispersion energy, $V_{elec}^{nb}$ is the electrostatic energy, and $V_{poly}^{nb}$ is the polynomial correction that we can obtain to reproduce the reference data. Although the previous expression was written in a general form for any n-body system, the repulsion and dispersion terms only appear for large monomers (when there are non-excluded pairs) and dimers. The MB-nrg PEFs have no explicit expression for three- or higher-body terms. The only term that survive at any n-body level is the electrostatics thorugh the classical polarization.\n",
    "\n",
    "Repulsion, dispersion and electrostatics can be calculated if teh monomer properties such as charges, polarizabilities, and dispersion coefficients are known. The MB-nrg models are though to be physically motivated, and all these properties are calculated from electronic structure calculations. Concretely, the charges are calculated performing a CM5 calculation with $\\omega$B97M-V and aug-cc-pvtz by default. The polarizabilities and C6 are obtained peforming an XDM calculation at the same level of theory, obtaining the C6 coefficients directly from the electronic structure output, and using the effective volumes to calculate the effective polarizability of each atom with the expression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\alpha ^{eff} = \\left( \\alpha^{free} \\frac{V^{eff}}{V^{free}} \\right) ^ {\\frac{4}{3}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\alpha^{free}$ is the polarizability of the atom by itslef in the gas phase, $V^{free}$ is the volume of that atom in the gas phase, and $V^{eff}$ can be obtained from the XDM calculation, being the volume of the atom in the environment of the molecule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `get_system_properties` performs the necessari electronic structure calculations to obtain charges, polarizabilities and C6 coefficients (if applicable) for the system.\n",
    "```\n",
    "get_system_properties(settings_file, config_path, geo_paths, distance_between=20, use_published_polarizabilities=True, method='wb97m-v', basis='aug-cc-pvtz', num_digits=4, virtual_sites=['X', 'Y', 'Z'])\n",
    "    Obtains information such as charges and pols that will be needed for the fitting.\n",
    "    \n",
    "    Qchem is required for this step to work.\n",
    "    \n",
    "    Args:\n",
    "        settings_path       - Local path to the file containing all relevent settings information.\n",
    "        config_path         - Local path to file to write the config file to.\n",
    "        geo_paths           - List of local paths to the optimized geometries to include in this fit config.\n",
    "        distance_between    - The Distance between each geometry in the qchem calculation. If the qchem calculation\n",
    "                does not converge, try different values of this.\n",
    "        use_published_polarizabilities - use published polarizabilites from\n",
    "                DOI: 10.1080/00268976.2018.1535143 rather than the ones Marc gave me to use.\n",
    "                Default: True.\n",
    "        method              - Method to use for charges, polarizabilities, and c6 constants.\n",
    "                Default: wb97m-v.\n",
    "        basis               - Basis to use for charges, polarizabilites, and c6 constants.\n",
    "                Default: aug-cc-pvtz.\n",
    "        num_digits            - Number of digits after the decimal point to include in charges, c6, and polarizabilites.\n",
    "                Default: 4\n",
    "        virtual_sites       - List of Symmetry labels that are virtual sites.\n",
    "                Default: [\"X\", \"Y\", \"Z\"]\n",
    "    \n",
    "    Returns:\n",
    "        charges             - List with the charges of each monomer [[mon1],[mon2],..]\n",
    "        pols                - List with the pols of each monomer [[mon1],[mon2],..]\n",
    "        C6                  - List with the C6 constants\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this function, the mandatory argument `config_path` is the path to the file where the config file will be written. The last mandatory argument `geo_paths` must eb a list containing, in same order as the symmetry, the optimized monomer XYZ file for each monomer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"config.ini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chg, pol, c6 = mbfit.get_system_properties(settings_nh3, config, geo_paths = [optimized_nh3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the charges have been computed and stored in `chg` from a CM5 calculation on the optimized NH3, the polarizabilites have been computed using the effective volumes on the optimized NH3 and stored in `pol`, and the C6 coefficients have been computed from a XDM calculation on a dimer of NH3, separated a long distance, and stored in `c6`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"charges\",chg)\n",
    "print(\"polarizabilities\",pol)\n",
    "print(\"C6\",c6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these properties calculated we can now write the configuration file that will be used to control the generation of the fitting code. The file will be written in `config`. To write the file, the function `write_config_file` must be called."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "write_config_file(settings_file, config_path, charges, pols, geo_paths, C6=[0.0], polfacs=None, d6=None, A=None, kmin=0.0, kmax=50.0, dmin=0.0, dmax=50.0, bmin=0.0, bmax=10.0, kmin_init=1.0, kmax_init=4.0, dmin_init=1.0, dmax_init=4.0, bmin_init=1.0, bmax_init=4.0, r_in=7.0, r_out=8.0, energy_range=20, alpha=0.0005, virtual_sites_label=['X', 'Y', 'Z'], var_intra='exp', var_inter='exp', var_virtual_sites='coul')\n",
    "    Writes the config file.\n",
    "    \n",
    "    Qchem is required for this step to work.\n",
    "    \n",
    "    Args:\n",
    "        settings_path       - Local path to the file containing all relevent settings information.\n",
    "        config_path         - Local path to file to write the config file to.\n",
    "        charges             - List with the charges of each monomer [[mon1],[mon2],..]\n",
    "        pols                - List with the pols of each monomer [[mon1],[mon2],..]\n",
    "        geo_paths           - List of local paths to the optimized geometries to include in this fit config.\n",
    "        C6                  - List with the C6 constants\n",
    "                Default: [0.0]\n",
    "        polfacs             - List with the polarizability factors of each monomer [[mon1],[mon2],..]\n",
    "                Default: None\n",
    "        d6                  - List with the d6 constants\n",
    "                Default: None\n",
    "        A                   - List with the buckingham A parameters\n",
    "                Default:  None\n",
    "        kmin                - Minimum value of k allowed while fitting\n",
    "                Default: 0.0\n",
    "        kmax                - Maximum value of k allowed while fitting\n",
    "                Default: 50.0\n",
    "        dmin                - Minimum value of d allowed while fitting\n",
    "                Default: 0.0\n",
    "        dmax                - Maximum value of d allowed while fitting\n",
    "                Default: 50.0\n",
    "        bmin                - Minimum value of b allowed while fitting\n",
    "                Default: 0.0\n",
    "        bmax                - Maximum value of b allowed while fitting\n",
    "                Default: 10.0\n",
    "        kmin_init           - Minimum value of k allowed in initialization\n",
    "                Default: 1.0\n",
    "        kmax_init           - Maximum value of k allowed in initialization\n",
    "                Default: 4.0\n",
    "        dmin_init           - Minimum value of d allowed in initialization\n",
    "                Default: 1.0\n",
    "        dmax_init           - Maximum value of d allowed in initialization\n",
    "                Default: 4.0\n",
    "        bmin_init           - Minimum value of b allowed in initialization\n",
    "                Default: 1.0\n",
    "        bmax_init           - Maximum value of b allowed in initialization\n",
    "                Default: 4.0\n",
    "        r_in                - Distance at which polynomials start to decay to 0\n",
    "                Default: 7.0\n",
    "        r_out               - Distance at which polynomials are 0\n",
    "                Default: 8.0\n",
    "        energy_range        - Value of DE in the weight expressions: w = (DE/(E-Emin+DE))^2\n",
    "                Default: 20.0\n",
    "        alpha               - Ridge regression parameter\n",
    "                Default: 0.0005\n",
    "        virtual_sites_label - List of Symmetry labels that are virtual sites.\n",
    "                Default: [\"X\", \"Y\", \"Z\"]\n",
    "        var_intra           - Type of variable used for intramolecular distances.\n",
    "                              exp = exp(-kr)\n",
    "                              exp0 = exp(-k(r-r0))\n",
    "                              coul = exp(-kr)/r\n",
    "                              coul0 = exp(-k(r-r0))/r\n",
    "                Default: exp\n",
    "        var_inter           - Type of variable used for intermolecular distances.\n",
    "                              exp = exp(-kr)\n",
    "                              exp0 = exp(-k(r-r0))\n",
    "                              coul = exp(-kr)/r\n",
    "                              coul0 = exp(-k(r-r0))/r\n",
    "                Default: exp\n",
    "        var_virtual_sites   - Type of variable used for distances involving polynomial virtual sites.\n",
    "                              exp = exp(-kr)\n",
    "                              exp0 = exp(-k(r-r0))\n",
    "                              coul = exp(-kr)/r\n",
    "                              coul0 = exp(-k(r-r0))/r \n",
    "                Default: coul\n",
    "    \n",
    "    Returns:\n",
    "        None.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The config file defines all the different features that can be tuned in the fitting procedure and the monomials functional form. The first arguments have already been introduced. The `polfac` argument, which is `None` by default, is a list of the same dimensions as `pol` containing the smearings to use in the Thole model. The advice is to use the default, which will set thos values to be the same as the atomic polarizabilities. Although in this example there is no need to do it, since all the pairs inside NH3 are excluded, the values of `A` and `d6` should be the ones from the TTM-nrg PEF. They can be ignored for now. `k_min/max` and `d_min/max`  control which is the minimum and maximum value allowed for the non-linear parameters of the polynomial: `k` and `d`. `b_min/max` controls the maximum and minimum values allowed when fitting the Buckingham potential for the non-linear parameter `b`. The same variants with `init` stablish the limits of the parameters when performing the first guess. The default values for all of them are recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained in the publications from the Paesani Lab, the polynomial correction for the two-body is applied up to a certain distance. To avoid a sudden change in the potential energy surface, a switch function that smoothly turns off the polynomials is used. In the previous function call, `r_in` and `r_out` are the distances in whcih the switch starts to go to 0, and when the switch is exactly 0, respectively. A 2 Angstrom buffer region starting at 6 or 7 Angstrom is recommended for two-body fits. One-body fits do not use a switch function and these values will be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value defined in `energy_range` (`DE` for short) will determine how different is the weight as a function of the energy. The weights are computed as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$w_i = \\left( \\frac{DE}{DE + (BE-BE_{min})} \\right) ^ 2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where DE is the energy range, and BE is the binding energy, being BE$_{min}$ the binding energy of the minimum energy structure. This meand than when the difference (BE-BE$_{min}$) is equal to DE, the weight of that configuration will be 0.25, having a maximum of 1.0 when BE = BE$_{min}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter `alpha` is the regularization parameter. The fitting procedure uses ridge regression (also known as Tikonov Regularization) to ensure that the linear parameters of the polynomials are not in a wide range of orders of magnitude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.write_config_file(settings_nh3, config, chg, pol, geo_paths = [optimized_nh3], C6=c6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MB-nrg fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set and the configuration file are key pieces to be able to perform the fit. Now the fitting code must be generated. The fitting code will be specific for the system that is being studied. The fitting code can be generated with the function `generate_mbnrg_fitting_code`, which will generate a new folder `fit_dir_path` with the source code of the fitting code. If MAPLE is not available, and the optimized polynomial files have not been obtained, one can use the direct gradients by setting `use_direct` to `True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "generate_mbnrg_fitting_code(settings_path, config_path, poly_in_path, \n",
    "                            poly_path, poly_order, fit_dir_path, use_direct=False)\n",
    "    Generates the fit code based on the polynomials for a system\n",
    "    \n",
    "    Args:\n",
    "        settings_path       - Local path to the file containing all relevent settings information.\n",
    "        config_path         - Local path to the dimer config file.\n",
    "        poly_in_path        - Local path to the the A3B2.in type file to read polynomial input from.\n",
    "        poly_path           - Local path to directory where polynomial files are.\n",
    "        poly_order          - The order of the polynomial in poly_path.\n",
    "        fit_dir_path        - Local path to directory to generate fit code in.\n",
    "        use_direct          - If true, it will use the direct polynomials instead of the mapleoptimized\n",
    "    \n",
    "    Returns:\n",
    "        None.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh3_monomer_fitcode_dir = \"fitcode_nh3_mbnrg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.generate_mbnrg_fitting_code(settings_nh3, config, poly_in_nh3, polynomial_directory_nh3, \n",
    "                                  polynomial_order_nh3, nh3_monomer_fitcode_dir, use_direct=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the code can be compiled. If needed, the Makefile inside `nh3_monomer_fitcode_dir/src` can be modified and manually compile the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.compile_fit_code(settings_nh3,nh3_monomer_fitcode_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fits will have a random initial guess with random numbers seeded wuth the time. It is strongly recommended to run at least 50 fits,although here we will just run 2 for the sake of the example. Depending on the number of terms and number of variables, the fits might take up to several hours. Thus it is convenient to have each fit prepared ina folder with a script that can be executed locally or in a supercomputer. FIrst, we prepare the fits by calling `prepare_fits`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "prepare_fits(settings_path, fit_dir_path, training_set_path, fits_path, DE=20, alpha=0.0005, num_fits=10, ttm=False, over_ttm=False)\n",
    "    Prepares fits to be run by creating directories with executable scripts in them.\n",
    "    \n",
    "    Each directory will contain a run_fit.sh script, which when ran will run one fit.\n",
    "    \n",
    "    The directories will appear in the directory with your other log files.\n",
    "    \n",
    "    Args:\n",
    "        settings_path       - Local path to the file containing all relevent settings information.\n",
    "        fit_dir_path        - Local path to the directory containing the compiled fitcode.\n",
    "        training_set_path   - Local path to training set to use for all the fits.\n",
    "        fits_path           - Local path to the directory to create the fits in.\n",
    "        DE                  - Low DE places more weight on low energy training set items. \n",
    "                              Large DE places even weight on all training set items. Weights w_n are computed as\n",
    "                              w_n = (DE / (E_n - E_min + DE))**2\n",
    "        alpha               - Weight for the regularization parameter in the fits. Large alpha means coefficients will\n",
    "                be smaller. (Less likely for one or more coefficients to blow up.)\n",
    "        num_fits            - How many new directories with executables to make. Existing ones will not be changed.\n",
    "        ttm                 - True if these are ttm fits. False otherwise.\n",
    "        over_ttm            - Only used if ttm is False, if enabled, will fit polynomials over ttm.\n",
    "    \n",
    "    Returns:\n",
    "        None.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this function, `fits_path` is the folder where the fits are going to be set up. DE should be set to the energy_range value, and alpha to the regularization parameter used in the config file. If the fit is a two-body fit, there is the option to use the polynomials purely as a correction on top of the TTM-nrg PEF by setting `over_ttm` to `True`. If `False`, the polynomials will take care of the repulsion and the correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits_nh3_monomer = \"fits_nh3_monomer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.prepare_fits(settings_nh3, nh3_monomer_fitcode_dir, training_set,fits_nh3_monomer,num_fits = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous function has generated several folders inside `fits_nh3_monomer`, with a `run.sh` script that can be executed externally if needed. MB-Fit provides with a function that will loop over the unconverged fits and run them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.execute_fits(settings_nh3,fits_nh3_monomer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And after the fits are done, the `retrieve_best_fit` function will look for the best fit and keep it in a separate folder called `best_fit`. The arguments of this function `fitted_nc_path` and `fitted_ttmnrg_params` are the paths to the files that will contain the encoded MB-nrg and TTM-nrg parameters respectively. Recommended to leave it as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "retrieve_best_fit(settings_path, fits_path, fitted_nc_path='mbnrg.nc', fitted_ttmnrg_params='ttm-nrg_params.dat')\n",
    "    Looks through all log files in all fit directories in the log path and finds the best fit.\n",
    "    \n",
    "    The best_fit will end up inside a directory in the logs directory called \"best_fit\".\n",
    "    \n",
    "    If any new fit is better than the current best fit, it will replace best_fit with the new\n",
    "    best one.\n",
    "    \n",
    "    Args:\n",
    "        settings_path       - Local path to the file containing all relevent settings information.\n",
    "        fits_path           - Local path to the directory to create the fits in.\n",
    "        fitted_nc_path      - Generate a .nc file with the parameters for the best fit at this location.\n",
    "        fitted_ttmnrg_params - Rename the output where the TTM-nrg params are to this name\n",
    "    \n",
    "    Returns:\n",
    "        None.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfit.retrieve_best_fit(settings_nh3,fits_nh3_monomer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the fits are done and there is a fit that meets our expectations, one can plot the correlation plots for the training and the test set using the tools provided in MB-fit with the function `get_correlation_data`. The function will return a list of energies that can be written and plotted with other programs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "get_correlation_data(settings_path, fitting_code_dir_path, fits_path, training_set, split_energy=None, min_energy_plot=0.0, max_energy_plot=50.0, correlation_prefix='correlation', correlation_directory='correlation', ttm=False, over_ttm=False, nc_path='mbnrg.nc', fitted_ttmnrg_params='ttm-nrg_params.dat')\n",
    "    Generates correltation data for the training/test set passed as argument\n",
    "    \n",
    "    Args:\n",
    "        settings_path         - Local path to the file containing all relevent settings information.\n",
    "        fitting_code_dir_path - Local path to the directory containing the compiled fitcode.\n",
    "        fits_path             - Local path to folder containing the fits\n",
    "        training_set          - Configurations to evaluate. They need the binding energy and n-b energy in this order in the comment line.\n",
    "        split_energy          - If not None, will split the correlation plot in two sets, low and high, depending on the value of the variable.\n",
    "        min_energy_plot       - Lower bound of the energy in the plot\n",
    "        max_energy_plot       - Upper bound of the energy in the plot\n",
    "        correlation_prefix    - Prefix for the correlation files that will be generated.\n",
    "        correlation_directory - Directory where all the correlation files will be put.\n",
    "        ttm                   - True if these are ttm fits. False otherwise.\n",
    "        over_ttm              - Only used if ttm is False, if enabled, will fit polynomials over ttm.\n",
    "        nc_path               - Netcdf file with the parameters for the best fit.\n",
    "        fitted_ttmnrg_params  - Name of the output where the TTM-nrg params\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energies_training = mbfit.get_correlation_data(settings_nh3, nh3_monomer_fitcode_dir, fits_nh3_monomer,\n",
    "                                       training_set, split_energy = 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energies_training = mbfit.get_correlation_data(settings_nh3, nh3_monomer_fitcode_dir, fits_nh3_monomer,\n",
    "                                       test_set, split_energy = 10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 Add files to MBX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(potential_fitting.generate_MBX_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_fitting.generate_MBX_files(mon_settings, config, mon_ids, \n",
    "                                     do_ttmnrg=False, mbnrg_fits_path=mbnrg_fit_path,  \n",
    "                                     MBX_HOME = None, version = \"v1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
